---
bibliography: Whitebib.bib
csl: ecology-letters.csl
editor_options:
  chunk_output_type: console
fontsize: 12pt
geometry: margin=1in
header-includes: \usepackage{float} \usepackage{lineno} \usepackage{setspace}
  \usepackage[round]{natbib} \bibpunct[; ]{(}{)}{,}{a}{}{,} \usepackage{color} \usepackage{totcount}
  \newtotcounter{citenum} \def\oldcite{} \let\oldcite=\bibcite \def\bibcite{\stepcounter{citenum}\oldcite}
  \usepackage{fancyhdr} \pagestyle{fancy} \fancyhf{} \fancyfoot[LE,LO]{\textcolor{red}{Preprint
  - This work has not yet been peer-reviewed}} \fancyfoot[RE,RO]{\thepage} \renewcommand{\headrulewidth}{0pt}
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    number_sections: no
  word_document: default
  html_document:
    df_print: paged
---




\begin{center}
\textbf{\Large State-level variation of initial COVID-19 dynamics in the United States: The role of local government interventions}
\vspace{5 mm}
	
\textsc{Easton R. White\footnote{Easton.White@uvm.edu}$^{,2}$, Laurent H\'{e}bert-Dufresne $^{3,4}$}
\vspace{3 mm}

\normalsize{\indent $^2$Department of Biology, University of Vermont, VT 05405, USA \\ {$^3$} Vermont Complex Systems Center, University of Vermont, VT 05405, USA \\ $^4$Department of Computer Science, University of Vermont, VT 05405, USA}
\end{center}


\vspace{3 mm}


```{r load_packages,echo=F,warning=F,message=F}
if (!require("pacman",character.only = TRUE))
  {
    install.packages("pacman",dep=TRUE)
    if(!require("pacman",character.only = TRUE)) stop("Package not found")
  }

# Keeping below source for github package. Ask Easton whether pacman works for github packages or not.
#devtools::install_github("rensa/stickylabeller")
pacman::p_load(patchwork, dplyr, tidyr, ggplot2, ggrepel, viridis, usmap, stargazer,tidyquant,ggpubr)
```


```{r, echo=F,message=F,warning=F}
# Load data for numbers in introduction
covid <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',header=T)



require(scales)
#sum(covid[,ncol(covid)])
#length(table(covid$Country.Region))
#format(as.Date(substr(names(covid)[ncol(covid)],2,8),format = '%m.%d.%y'),'%B %d')
```



# Introduction

The global COVID-19 (caused by the SARS-CoV-2 virus) outbreak began in Wuhan, China in late 2019 [@WHO2020]. As of `r paste(format(as.Date(substr(names(covid)[ncol(covid)-1],2,8),format = '%m.%d.%y'),'%B %d'),sep='')`^th^, `r comma(sum(covid[,ncol(covid)-1]))` cases have been reported across `r length(table(covid$Country.Region))` countries and regions. 


# Results and Discussion



<!--Load data and start analyses-->

```{r updated_data_cleaning,echo=F,eval=T,warning=F,message=F}
# Load data here automatically
require(dplyr)
require(tidyr)

source('CompileTimeSeries.R')

`%notin%` <- Negate(`%in%`)
# Subset data just for the USA
covid <- covid %>%
  filter(Country.Region == 'US') %>%
  filter(!grepl(',', Province.State)) %>% 
  filter(Province.State %notin% c('Unassigned Location (From Diamond Princess)','Grand Princess Cruise Ship','Wuhan Evacuee','US','Diamond Princess','Recovered','Grand Princess','Virgin Islands','Guam'))

# Change data to long format and adjust date variable
covid <- covid %>%
  #gather('Date','Cases',-Province.State,-Country.Region,-Lat,-Long) %>%
  #mutate(Date = sub('.',replacement = '',Date)) %>%
  mutate(Date = as.Date(Date,format='%m-%d-%y')) %>%
  mutate(DayOfYear = as.numeric(strftime(Date, format = "%j")))
```

```{r measurements_by_states2,echo=F,warning=F,message=F, fig.height=5,eval=T,fig.cap='(a) The log number of cases over time for each individual state for the 10 days since their first day of 25 total cases. (b) The log number of cases over time for each individual state for the next 10 days. The light grey diagonal lines represent the growth trajectory for doubling times of 2, 4, and 10 days. The log number of the starting value (initial number of cases on first day when at least 25 cases were recorded) had to be subtracted on the y-axis to standardize the graph across states. (c) Rolling doubling times calculated over 10-day windows for each individual states. (d) Distributions of state-level doubling times early and more recent in the course of the outbreak.\\label{fig:measurements_by_states}'}

# Filter out local county data and focus on states with at least 3 data points of 25 cases or more

require(ggplot2) 
require(ggrepel)
require(viridis)


covid_by_state <- covid %>%
  group_by(Date,Province.State) %>%
  summarise(Cases = sum(Cases),Deaths=sum(Deaths),Recovered = sum(Recovered), DayOfYear = mean(DayOfYear)) %>%
  filter(Cases > 24) %>%
  group_by(Province.State) 

# Record first date of more than 25 cases
covid_by_state <- covid_by_state %>%
  group_by(Province.State) %>%
  mutate(first_confirmed = Date[which(Cases>24)[1]]) %>%
  #mutate(first_confirmed = as.Date('2020-04-05')) %>%
  #filter(Date>'2020-04-04') %>%
  group_by(Province.State) %>%
  mutate(starting_value = min(Cases)) %>%
  mutate(DaysSince25 = as.Date(Date,format='%m.%d.%y')-as.Date(first_confirmed,format='%m.%d.%y'))




#%>% filter(DayOfYear>97)

states_early <- ggplot(data=covid_by_state %>% filter(DaysSince25<11),aes(x=DaysSince25, y=(log(Cases)) - (log(starting_value)),color=Province.State))  + 
  geom_abline(slope = log(2)/2, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/4, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/10, intercept = 0,color='lightgrey',size=2) +
  scale_color_viridis(discrete=T,begin = 0.1,end=0.9,option='viridis') +
  geom_line(alpha=0.5) + 
  theme_bw() + theme(legend.position = "none",axis.title.x = element_text(size = 10),axis.title.y = element_text(size = 10),panel.border = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + 
  ylab('log (Cases) - log (Starting value)') + xlab('Days since 25 cases recorded') + 
  annotate("text", x=6, y=2.5, label='doubling every 2 days', size=3) +
  annotate("text", x=7, y=1.2, label='doubling every 4 days', size=3) + 
  annotate("text", x=7.5, y=0.5, label='doubling every 10 days', size=3) +
  coord_cartesian(xlim =c(0.5,10.5),ylim =c(-0.1,4.5)) 




######### TRENDS IN NEXT 10 DAYS ######

#%>% filter(DayOfYear>97)


covid_by_state <- covid %>%
  group_by(Date,Province.State) %>%
  summarise(Cases = sum(Cases),Deaths=sum(Deaths),Recovered = sum(Recovered), DayOfYear = mean(DayOfYear)) %>%
  filter(Cases > 24) %>%
  group_by(Province.State) 

# Record first date of more than 25 cases
covid_by_state <- covid_by_state %>%
  group_by(Province.State) %>%
  mutate(first_confirmed = Date[which(Cases>24)[1]]) %>%
  mutate(DaysSince25 = as.Date(Date,format='%m.%d.%y')-as.Date(first_confirmed,format='%m.%d.%y')) %>%
  filter(DaysSince25>10 & DaysSince25<21) %>%
  group_by(Province.State) %>%
  mutate(starting_value = min(Cases)) 


#%>% filter(DayOfYear>97)

states_late <- ggplot(data=covid_by_state,aes(x=DaysSince25-11, y=(log(Cases)) - (log(starting_value)),color=Province.State))  + 
  geom_abline(slope = log(2)/2, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/4, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/10, intercept = 0,color='lightgrey',size=2) +
  scale_color_viridis(discrete=T,begin = 0.1,end=0.9,option='viridis') +
  geom_line(alpha=0.5) + 
  theme_bw() + theme(legend.position = "none",axis.title.x = element_text(size = 10),axis.title.y = element_text(size = 10),panel.border = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))   +
  ylab('') + xlab('Next 10 days') + 
  annotate("text", x=6, y=2.5, label='doubling every 2 days', size=3) +
  annotate("text", x=7, y=1.2, label='doubling every 4 days', size=3) + 
  annotate("text", x=7.5, y=0.5, label='doubling every 10 days', size=3) +
  coord_cartesian(xlim =c(0.5,10.5),ylim =c(-0.1,4.5)) 


###########################################

# Rolling doubling times

covid_by_state <- covid %>%
  group_by(Date,Province.State) %>%
  summarise(Cases = sum(Cases),Deaths=sum(Deaths),Recovered = sum(Recovered), DayOfYear = mean(DayOfYear)) %>%
  filter(Cases > 24) 

time_of_25plus_cases <- covid_by_state %>%
  group_by(Province.State) %>%
  summarize(first_confirmed = Date[which(Cases>24)[1]])
covid_by_state = left_join(covid_by_state,time_of_25plus_cases,by="Province.State")

covid_by_state$DaysSince25 <- as.numeric(as.Date(covid_by_state$Date,format='%m.%d.%y')-as.Date(covid_by_state$first_confirmed,format='%m.%d.%y'))


calc_slope <- function(y){
    y = as.numeric(na.omit(y))
    x = 1:length(y)
    regression = summary(lm(log(y)~x))
    return(as.numeric(regression$coefficients[2,1]))
}

require(tidyquant)

rollmean <- covid_by_state %>%
    group_by(Province.State) %>%
  tq_mutate(
    # tq_mutate args
    select     = Cases,
    mutate_fun = rollapply, 
    width      = 10,
    align      = "right",
    FUN        = calc_slope,
    col_rename = "mean_10"
  ) 


rollmean_time <- ggplot(data = rollmean,aes(x=DaysSince25,y=log(2)/mean_10,color=Province.State)) + geom_line() +  scale_color_viridis(discrete=T,begin = 0.1,end=0.9,option='viridis') +
  geom_line(alpha=0.5) + 
  theme_bw() + theme(legend.position = "none",axis.title.x = element_text(size = 10),axis.title.y = element_text(size = 10),panel.border = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))   +
  ylab('Rolling doubling time') + xlab('Days since 25 cases') 



# Distribution of doubling times

early_rollmean <- rollmean %>%
  filter(DaysSince25==10)
early_rollmean$timing <- 'First 10 days'

late_rollmean <- rollmean %>%
  filter(DaysSince25==20)
late_rollmean$timing <- 'Next 10 days'

combined_rollmean = rbind(early_rollmean,late_rollmean)

rollmean_dist <- ggplot(combined_rollmean, aes(x=log(2)/mean_10),color=as.factor(timing)) +  geom_density(alpha=.2,aes(fill=as.factor(timing) )) + theme_bw() + theme(legend.position = c(0.65, 0.65),axis.title.x = element_text(size = 10),axis.title.y = element_text(size = 10),panel.border = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))   +
  ylab('Frequency') + xlab('Doubling time (days)') + labs(fill = 'Time window')





require(ggpubr)
figure=ggarrange(states_early,states_late,rollmean_time,rollmean_dist, ncol=2, nrow=2, common.legend = FALSE, labels=c('(a)','(b)','(c)','(d)'),label.x = 0.85, label.y = 0.95,font.label='plain')
annotate_figure(figure,bottom = text_grob(" ", color = "black",hjust = 0.9,vjust=-1, x = 0.6, size = 10),left = text_grob(" ", color = "black", rot = 90,size=10,vjust=2,hjust=0.4))
```




```{r, overall_doubling, echo=F}
# Update to date doubling time between states
covid_by_state <- covid %>%
  group_by(Date,Province.State) %>%
  summarise(Cases = sum(Cases),Deaths=sum(Deaths),Recovered = sum(Recovered), DayOfYear = mean(DayOfYear)) %>%
  filter(Cases > 24) 


# Record first date of more than 25 cases
covid_by_state <- covid_by_state %>%
  group_by(Province.State) %>%
  filter(length(Cases)>3) %>%
  mutate(first25_confirmed = Date[which(Cases>24)[1]],  first150_confirmed = Date[which(Cases>149)[1]]) %>%
  group_by(Province.State) %>%
  mutate(starting_value = min(Cases)) %>%
  mutate(DaysSince25 = as.Date(Date,format='%m.%d.%y')- as.Date(first25_confirmed,format='%m.%d.%y'), DaysSince150 = as.Date(Date,format='%m.%d.%y')-as.Date(first150_confirmed,format='%m.%d.%y')) %>%
  mutate(first25_confirmed = as.numeric(format(first25_confirmed,format='%j')), first150_confirmed = as.numeric(format(first150_confirmed,format='%j'))) 

# Doubling time for whole time series
#covid_by_state_doubling_time <- covid_by_state %>%
#  group_by(Province.State) %>%
#  mutate(exponential_param = calc_slope(Cases), doubling_time = log(2)/calc_slope(Cases)) %>% 
#  arrange(doubling_time)

# Calculate doubling times for whole, early, and late
covid_by_state_doubling_time <- covid_by_state %>%
  group_by(Province.State) %>%
  mutate(exponential_param = calc_slope(Cases), doubling_time = log(2)/calc_slope(Cases),
         exponential_param_early = calc_slope(Cases[DaysSince25<7]), doubling_time_early = log(2)/calc_slope(Cases[DaysSince25<7]),
         exponential_param_late = calc_slope(Cases[DayOfYear>max(DayOfYear)-7]), doubling_time_late = log(2)/calc_slope(Cases[DayOfYear>max(DayOfYear)-7]),exponential_param_first3weeks = calc_slope(Cases[DaysSince25<22]), doubling_time_first3weeks = log(2)/calc_slope(Cases[DaysSince25<22])) %>% 
  arrange(doubling_time)


```



```{r,overall_doubling_by_predictors,echo=F,warning=F,fig.height=8,message=F,eval=T,fig.cap='Doubling time (in number of days) versus (a) log (population density), (b) population density in urban areas, (c) population density in rural areas, (d) population percent in urban areas, (e) population percent in urban centers, (f) life expectancy (years), (g) percent of population above age 65, (h) gross income per capita (in 1000s USD), (i) expected years of schooling, (j) yearly flu vaccination rate, (k) volunteer rate, and (l) tightness score. \\label{fig:overall_doubling_by_predictors}'}
# Combine doubling time with demographic and other indicators 

# Set up data frame of demographic information
require(usmap)
state_demo <- statepop
names(state_demo)[3] <- 'Province.State'

# Add information on population density, rural vs urban
state_demo <- left_join(state_demo,read.csv('US_states_correlates/PctUrbanRural_State.csv',header=T))

state_demo$POPDEN_log <- log(state_demo$POP_ST/state_demo$AREA_ST)

# Add information on age of population
state_demo <- left_join(state_demo,read.csv('US_states_correlates/percent65plus.csv',header=T))

# Add information on Vaccine and Volunteer rates
state_demo <- left_join(state_demo,read.csv('US_states_correlates/US_State_VaccinationRates.csv',header=T))
state_demo <- left_join(state_demo,read.csv('US_states_correlates/US_State_VolunteerRates.csv',header=T))

# Add wealth and schooling indicators
state_demo <- left_join(state_demo,read.csv('US_states_correlates/GDL-Indicators-(2018)-data.csv',header=T))

state_demo <- left_join(state_demo,read.csv('US_states_correlates/TightnessScores_HarringtonGelfand2014.csv',header=T))

# Add timing of various state-level government actions
state_demo <- left_join(state_demo,read.csv('US_states_correlates/States_by_ActionsApr3.csv',header=T,stringsAsFactors = F))
state_demo$StateOfEmergency = as.numeric(format(as.Date(state_demo$StateOfEmergency,format = "%m/%d/%y"),format='%j'))
state_demo$LimitGatherings = as.numeric(format(as.Date(state_demo$LimitGatherings,format = "%m/%d/%y"),format='%j'))
state_demo$ClosePublicSchools = as.numeric(format(as.Date(state_demo$ClosePublicSchools,format = "%m/%d/%y"),format='%j'))
state_demo$RestrictRestaurants = as.numeric(format(as.Date(state_demo$RestrictRestaurants,format = "%m/%d/%y"),format='%j'))
state_demo$RestrictBusinesses = as.numeric(format(as.Date(state_demo$RestrictBusinesses,format = "%m/%d/%y"),format='%j'))
state_demo$StayAtHome = as.numeric(format(as.Date(state_demo$StayAtHome,format = "%m/%d/%y"),format='%j'))

all_data_by_state <- left_join(state_demo,covid_by_state_doubling_time)

all_data_by_state <- all_data_by_state %>%
  group_by(Province.State) %>%
  filter(DayOfYear == max(DayOfYear))

# Build plots of various demographic and indicator correlates

par(mfrow=c(4,3),mar=c(4,0.3,1,0),oma=c(0,5,0.5,0.5))

# Density factors
plot(all_data_by_state$POPDEN_log,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='log (Population density)')
plot(all_data_by_state$POPDEN_URBAN,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Population density in urban areas',yaxt='n')
plot(all_data_by_state$POPDEN_RURAL,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Population density in rural areas',yaxt='n') 
plot(all_data_by_state$POPPCT_URBAN,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Population percent in urban areas')
plot(all_data_by_state$POPDEN_UC,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Population percent in urban centers',yaxt='n')

# Health and schooling
plot(all_data_by_state$Life_expectancy,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Life expectancy (years)',yaxt='n')
plot(all_data_by_state$Percent65_plus,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Percent of population above 65+')
plot(all_data_by_state$GNI_per_capita_inthousands_of_USD_2011PPP.,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Gross income per capita',yaxt='n')
plot(all_data_by_state$Expected_years_schooling,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Expected years of schooling',yaxt='n')

# Other indicators
plot(all_data_by_state$Vaccination_Rate,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Yearly flu vaccination rate')
plot(all_data_by_state$VolunteerRate2015_Americorps,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Volunteer rate',yaxt='n')

# Tightness score

plot(all_data_by_state$TightnessScore,all_data_by_state$doubling_time,pch=16,las=1,ylab='',xlab='Tightness score',yaxt='n')

mtext(text = 'Doubling time',side = 2,line = 2,outer = T,cex=1.2)

```


```{r,overall_doubling_by_actions,echo=F,warning=F,message=F, fig.height=6,eval=T,fig.cap='Doubling time (in number of days) across the US states for five different statewide government restrictions: (a) limit gatherings (usually to less than 10 people) by first day of 25 cases, (b) close public schools by first day of 25 cases, (c) restrict restaurants by first day of 25 cases, (d) restrict non-essential businesses by first day of 150 cases, (e) stay at home order by first day of 150 cases, and (f) total number of restrictions before number of cases threshold. \\label{fig:overall_doubling_by_actions}'}
# Combine doubling time with government actions and build plots


# Create binary data 

#all_data_by_state$StateOfEmergency <- as.numeric(all_data_by_state$StateOfEmergency<all_data_by_state$DayOf25) + 1
all_data_by_state$LimitGatherings <- as.numeric(all_data_by_state$LimitGatherings<all_data_by_state$first25_confirmed) 
all_data_by_state$LimitGatherings[is.na(all_data_by_state$LimitGatherings)] = 0 
all_data_by_state$ClosePublicSchools <- as.numeric(all_data_by_state$ClosePublicSchools<all_data_by_state$first25_confirmed) 
all_data_by_state$ClosePublicSchools[is.na(all_data_by_state$ClosePublicSchools)] = 0
all_data_by_state$RestrictRestaurants <- as.numeric(all_data_by_state$RestrictRestaurants<all_data_by_state$first25_confirmed) 
all_data_by_state$RestrictRestaurants[is.na(all_data_by_state$RestrictRestaurants)] = 0
all_data_by_state$RestrictBusinesses <- as.numeric(all_data_by_state$RestrictBusinesses<all_data_by_state$first150_confirmed) 
all_data_by_state$RestrictBusinesses[is.na(all_data_by_state$RestrictBusinesses)] = 0
all_data_by_state$StayAtHome <- as.numeric(all_data_by_state$StayAtHome<all_data_by_state$first150_confirmed) 
all_data_by_state$StayAtHome[is.na(all_data_by_state$StayAtHome)] =0

all_data_by_state$total_score = (all_data_by_state$LimitGatherings) + (all_data_by_state$ClosePublicSchools) +
(all_data_by_state$RestrictRestaurants) +
(all_data_by_state$RestrictBusinesses) + (all_data_by_state$StayAtHome) 



# Build plot
par(mfrow=c(2,3),mar=c(4.5,0.5,1,0),oma=c(0,5,0.5,0.5))
#boxplot(all_data_by_state$doubling_time~all_data_by_state$StateOfEmergency,las=1)
boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$LimitGatherings,las=1,xlab='Limit gatherings',xaxt='n')
axis(side = 1,at = 1:2,labels = c('No','Yes'))
points(all_data_by_state$LimitGatherings+1,all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(a)',side = 3,line = -2,adj = 0.95)

boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$ClosePublicSchools,las=1,xlab='Close schools',xaxt='n',yaxt='n')
axis(side = 1,at = 1:2,labels = c('No','Yes'))
points(all_data_by_state$ClosePublicSchools+1,all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(b)',side = 3,line = -2,adj = 0.95)

boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$RestrictRestaurants,las=1,xlab='Restrict restaurants',xaxt='n',yaxt='n')
#text(2,5.2,labels = '*significant difference')
axis(side = 1,at = 1:2,labels = c('No','Yes'))
points(all_data_by_state$RestrictRestaurants+1,all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(c)',side = 3,line = -2,adj = 0.95)

boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$RestrictBusinesses,las=1,xlab='Restrict businesses',xaxt='n')
#text(2,5.2,labels = '*significant difference')
axis(side = 1,at = 1:2,labels = c('No','Yes'))
points(all_data_by_state$RestrictBusinesses+1,all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(d)',side = 3,line = -2,adj = 0.95)

boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$StayAtHome,las=1,xlab='Stay at home mandate',xaxt='n',yaxt='n')
axis(side = 1,at = 1:2,labels = c('No','Yes'))
points(all_data_by_state$StayAtHome+1,all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(e)',side = 3,line = -2,adj = 0.95)

all_data_by_state$total_score[all_data_by_state$total_score==5]=4
boxplot(all_data_by_state$doubling_time_first3weeks~all_data_by_state$total_score,las=1,xlab='Number of state actions',yaxt='n',xaxt='n')
axis(side = 1,at = 1:5,labels = c('None','1','2','3','4 or 5'))
points((all_data_by_state$total_score+1),all_data_by_state$doubling_time_first3weeks,pch=16)
mtext(text = '(f)',side = 3,line = -2,adj = 0.95)

mtext(text = 'Doubling time (days)',side = 2,outer = T,line=2.5,cex.lab=1.2)

```




```{r, eval=T,out.width="0.8\\linewidth", include=TRUE, fig.align="center", fig.cap="Rank distribution of different interventions. Per state, every intervention is given a rank from 1 to 6 depending on when it was implemented (1 being the first put into place) and ties are given an average rank (e.g. 2.5 for tied 2nd and 3rd rank). \\label{fig:timing_of_interventions}", echo=FALSE}
knitr::include_graphics("US_state-level_dynamics_COVID19_manuscript_files/figure-latex/intervention_rankings.pdf")
```





```{r, finding_best_model,eval=T,echo=F,results='asis',warning=FALSE,message=FALSE,error=FALSE}
require(MASS)

overall_doubling <- with(na.omit(all_data_by_state),lm(doubling_time_first3weeks~RestrictBusinesses + ClosePublicSchools + LimitGatherings + StayAtHome + RestrictRestaurants + POPDEN_log + POPPCT_RURAL + Percent65_plus + Vaccination_Rate + VolunteerRate2015_Americorps  + GNI_per_capita_inthousands_of_USD_2011PPP. + Expected_years_schooling + TightnessScore))
overall_doubling_lm <- stepAIC(overall_doubling,direction='both',trace = FALSE)

early_doubling <- with(na.omit(all_data_by_state),lm(doubling_time_early~RestrictBusinesses + ClosePublicSchools + LimitGatherings + StayAtHome + RestrictRestaurants + POPDEN_log + POPPCT_RURAL + Percent65_plus + Vaccination_Rate + VolunteerRate2015_Americorps  + GNI_per_capita_inthousands_of_USD_2011PPP. + Expected_years_schooling + TightnessScore))
early_doubling_lm <- stepAIC(early_doubling,direction='both',trace = FALSE)

#summary(fit1_lm)

require(stargazer)
stargazer(early_doubling_lm,overall_doubling_lm, type = "latex", title="Best fitting linear models (according to AIC) and corresponding parameter estimates for the doubling time both early (first 7 days since 25 cases) and for the entire time period.\\label{tab:best_fit_model}", dep.var.labels=c("Early doubling time","Overall doubling time"),covariate.labels=c("Close schools","Restrict restaurants","log (Population density)","Vaccination rate","GNI per capita","Population percent in rural areas","Tightness score"),omit.stat=c("LL","ser","f"), no.space=TRUE,ci=TRUE,model.numbers = FALSE, notes = "",header=FALSE)

```



<!--

## Data sources

- population density and distribution (2010 US Census Bureau https://www.census.gov/programs-surveys/geography/guidance/geo-areas/urban-rural/2010-urban-rural.html)   
- percent of population over age 65 (U.S. Census Bureau, Vintage 2018 Population Estimates https://www.prb.org/which-us-states-are-the-oldest/)  
- life expectancy, income per capita, and expected years of schooling (Global Data Lab https://globaldatalab.org/shdi/download/2018/indicators/USA/?interpolation=0&extrapolation=0&nearest_real=0&format=csv)  
- yearly flu vaccination rate (ChildVaxView CDC https://worldpopulationreview.com/states/vaccination-rates-by-state/)  
- volunteer rate (2015 Corporation for National and Community Service data https://www.nationalservice.gov/vcla/state-rankings-volunteer-rate)  
- tightness scores @Harrington2014  
- testing rates by state (COVID Tracking Project https://covidtracking.com/)  
-->



\clearpage

# Supplemental figures

\setcounter{figure}{0}
\renewcommand{\thefigure}{S\arabic{figure}}

```{r cases_vs_time,echo=F,warning=F,message=F, fig.height=4,eval=T,fig.cap='(Left panel) Cases versus time for the whole United States. (Right panel) Log number of cases versus time for the whole United States. The red, dashed line is the line of best fit for all the data and the blue, solid line is the line of best fit since Feburary 29th. \\label{fig:cases_vs_time}'}
# Basic plots of cases over time and broken up by state (this might be in the methods section)

source('rollingmean.R')
US_cases_by_day <- covid %>%
  group_by(Date) %>%
  summarize(total_cases = sum(Cases)) %>%
  mutate(DayOfYear=as.numeric(strftime(Date, format = "%j"))-min(as.numeric(strftime(Date, format = "%j"))))



#jpeg('cases_vs_time-1.jpeg',width = 7, height = 5, units='in',res=500)
par(mfrow=c(1,2),oma=c(1,1.5,0.5,0.5),mar=c(4,4,0.5,0.5))
#plot(US_cases_by_day$Date,US_cases_by_day$total_cases,las=1,type='o',pch=16, ylab = '',xlab='',ylim=c(0,6e05))
#mtext(text = 'Total number of US cases',cex=1.2,side = 2,line = 3.5)
#points(US_cases_by_day$Date,0.1875+0.11667*US_cases_by_day$Date)
#US_cases_by_day = US_cases_by_day[US_cases_by_day$total_cases>0,]
#dude=summary(lm(log(US_cases_by_day$total_cases)~US_cases_by_day$Date))
plot(US_cases_by_day$Date,US_cases_by_day$total_cases,las=1,type='p',pch=16, ylab = ' ',xlab='',log='y')
mtext(text = 'Total number of US cases',cex=1.2,side = 2,line = 3.8)
mtext(text = 'Date',side = 1,line = -1,outer = T,cex = 1.4,adj = 0.55)
#fit_lm <- lm(log(US_cases_by_day$total_cases)~US_cases_by_day$Date)
#points(US_cases_by_day$Date,exp(fit_lm$fitted.values),type='l',lwd=2,col=2,lty=2)

require(tidyquant)

rollmean <- US_cases_by_day %>%
  tq_mutate(
    # tq_mutate args
    select     = total_cases,
    mutate_fun = rollapply, 
    width      = 10,
    align      = "right",
    FUN        = calc_slope,
    col_rename = "mean_10"
  ) 


plot(rollmean$Date,log(2)/rollmean$mean_10,type='o',pch=16,las=1,ylab='',xlab='',cex.lab=1.2,ylim=c(1.8,25))
mtext(text = 'Doubling time (10-day windows)',cex=1.2,side = 2,line = 2)


# Plot regression line for data starting on Feb 29th
#fit_lm2 <- lm(log(US_cases_by_day$total_cases[39:nrow(US_cases_by_day)])~US_cases_by_day$Date[39:nrow(US_cases_by_day)])
#points(US_cases_by_day$Date[39:nrow(US_cases_by_day)],exp(fit_lm2$fitted.values),type='l',lwd=2,lty=1,col='blue')
#dev.off()

```

\clearpage

```{r measurements_by_states_overall,echo=F,warning=F,message=F, fig.height=5,eval=T,fig.cap='The log number of cases over time for each individual state that recorded more than 25 cases over at least three days. The light grey diagonal lines represent the growth trajectory for doubling times of 2, 4, and 10 days. The log number of the starting value (intial number of cases on first day when at least 25 cases were recorded) had to be subtracted on the y-axis to standarize the graph across states. \\label{fig:measurements_by_states_overall}'}

# Filter out local county data and focus on states with at least 3 data points of 25 cases or more
covid_by_state <- covid %>%
  group_by(Date,Province.State) %>%
  summarise(Cases = sum(Cases),Deaths=sum(Deaths),Recovered = sum(Recovered), DayOfYear = mean(DayOfYear)) %>%
  filter(Cases > 24) 

# Record first date of more than 25 cases
covid_by_state <- covid_by_state %>%
  group_by(Province.State) %>%
  mutate(first_confirmed = Date[which(Cases>24)[1]]) %>%
  #mutate(first_confirmed = as.Date('2020-04-05')) %>%
  #filter(Date>'2020-04-04') %>%
  group_by(Province.State) %>%
  mutate(starting_value = min(Cases)) %>%
  mutate(DaysSince25 = as.Date(Date,format='%m.%d.%y')-as.Date(first_confirmed,format='%m.%d.%y'))


require(ggplot2) 
require(ggrepel)
require(viridis)

#%>% filter(DayOfYear>97)

states <- ggplot(data=covid_by_state,aes(x=DaysSince25, y=(log(Cases)) - (log(starting_value)),color=Province.State))  + 
  geom_abline(slope = log(2)/2, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/4, intercept = 0,color='lightgrey',size=2) +
  geom_abline(slope = log(2)/10, intercept = 0,color='lightgrey',size=2) +
  scale_color_viridis(discrete=T,begin = 0.1,end=0.9,option='viridis') +
  geom_line(alpha=0.5) + 
  theme_bw() + theme(legend.position = "none",axis.title.x = element_text(size = 14),axis.title.y = element_text(size = 14),panel.border = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + 
  geom_label_repel(data = subset(covid_by_state, DayOfYear== max(DayOfYear)),aes(label = Province.State),nudge_x = 0.1,na.rm = TRUE,segment.color = NA,fill=NA,label.size = NA,box.padding = 0) + 
  coord_cartesian(xlim =c(0.5,50),ylim =c(-0.1,9.5)) +
  ylab('log (Cases) - log (Starting value)') + xlab('Days since 25 cases recorded') + 
  annotate("text", x=16, y=6.2, label='doubling every 2 days', size=3) +
  annotate("text", x=21, y=4.1, label='doubling every 4 days', size=3) + 
  annotate("text", x=22, y=1.5, label='doubling every 10 days', size=3) #+
 # annotate("text", x=0.1, y=8, label='Created by @eastonrwhite', size=3,hjust = 0) +
  #annotate("text", x=0.1, y=7.6, label='Data from John Hopkins University/CDC', size=3,hjust = 0) 
states
  
#\ggsave(filename = paste('covid_by_state_daily_updates/state_responses',substr(Sys.time(),0,10),'.jpeg',sep=''),plot = states,device = 'jpeg',width = 10,height=6,units='in',dpi=500)

#library(plotly)
#gg <- ggplotly(states, tooltip = "Province.States")
#highlight(gg, defaultValues = "Florida")
```

\clearpage

```{r measurements_by_states_map,echo=F,warning=F,message=F, fig.height=5,eval=T,fig.cap='Doubling time (in number of days) for the first three weeks after a state reached 25 cases.\\label{fig:measurements_by_states_map}'}


#source('rollingmean.R')

# Which states have largest doubling time???

covid_by_state_doubling_time <- covid_by_state %>%
  filter(DaysSince25<22) %>%
  group_by(Province.State) %>%
  summarize(exponential_param_first3weeks = calc_slope(Cases), doubling_time_first3weeks = log(2)/calc_slope(Cases)) %>% 
  arrange(doubling_time_first3weeks)

# Add vector for state abbreviations
require(usmap)
state_pop <- statepop
names(state_pop)[3] <- 'Province.State'
covid_by_state_doubling_time <- left_join(covid_by_state_doubling_time,state_pop)


doubling_map <- plot_usmap(data = covid_by_state_doubling_time, values = "doubling_time_first3weeks", labels=FALSE) + scale_fill_viridis(begin=0.1,end=0.9) +
  theme(legend.position = "right") + 
  theme(panel.background = element_rect(color = "black")) + 
  labs(fill='Doubling time (days)') #+
 # labs(caption = "Created by: @eastonrwhite, Data from John Hopkins University/CDC",fill='Doubling time (days)',title=paste('Doubling time (days) as of',substr(Sys.time(),1,10)))
doubling_map

#ggsave(filename = paste('covid_by_state_daily_updates/doubling_map',substr(Sys.time(),0,10),'.jpeg',sep=''),plot = doubling_map,device = 'jpeg',width = 10,height=6,units='in',dpi=500)

```

\clearpage


```{r, overall_doubling_by_testkits,echo=F,warning=F,message=F, fig.height=5,eval=T,fig.cap='Doubling time (in number of days) for each US state according to their per-capita testing rates (a) early in the outbreak state (within the first week since 25 cases) and (b) for the entire time series. \\label{fig:overall_doubling_by_testkits}'}

# Test kit data over time with sensitivity
testkits <- read.csv('http://covidtracking.com/api/states/daily.csv',header=T)
testkits$date <- as.Date(as.character(testkits$date),'%Y%m%d')
testkits$percent_positive <- testkits$positive/testkits$total

testkits <- testkits %>%
  group_by(state) %>%
  arrange(date) %>%
  mutate(first_confirmed = date[which(positive>24)[1]]) %>%
  group_by(state) %>%
  mutate(starting_value = min(positive)) %>%
  mutate(DaysSince25 = as.Date(date,format='%m.%d.%y')-as.Date(first_confirmed,format='%m.%d.%y'))  

  
  
require(usmap)
state_pop <- statepop[,2:4]
names(state_pop)[1] <- 'state'
state_pop = rbind(state_pop,c('VI','U.S. Virgin Islands',107710))
state_pop = rbind(state_pop,c('PR','Puerto Rico',3473000))
state_pop = rbind(state_pop,c('GU','Guam',161797))
state_pop = rbind(state_pop,c('AS','American Samoa',55537))
state_pop = rbind(state_pop,c('MP','Northern Mariana Islands',54816 ))
state_pop$pop_2015 <- as.numeric(state_pop$pop_2015)

testkits <- left_join(testkits,state_pop)

ranking_states_by_tests <- testkits %>%
  #filter(date == max(date)) %>%
  rename(abbr = state) %>%
  group_by(abbr) %>%
  mutate(testkits_per_capita_recent = total[date==max(date)]/pop_2015[date==max(date)],testkits_per_capita_early = total[DaysSince25==10]/pop_2015[DaysSince25==10]) 


all_data_by_state2 <- left_join(all_data_by_state %>% filter(Date==max(Date)),ranking_states_by_tests %>% filter(date==max(date)),by='abbr')


par(mfrow=c(1,2),oma=c(1,1.5,0.5,0.5),mar=c(4,4,0.5,0.5))
plot(all_data_by_state2$testkits_per_capita_early,all_data_by_state2$doubling_time_early,las=1,pch=16,ylab='Early doubling time',xlab='Early test kits per capita',cex.lab=1.2,xlim=c(0,1.1*max(all_data_by_state2$testkits_per_capita_early)))
text(all_data_by_state2$testkits_per_capita_early,all_data_by_state2$doubling_time_early,labels = all_data_by_state2$abbr,cex=0.7,pos=4)
mtext(text = '(a)',side = 3,line = -1.5,adj = 0.95)

plot(all_data_by_state2$testkits_per_capita_recent,all_data_by_state2$doubling_time_first3weeks,las=1,pch=16,ylab='Overall doubling time',xlab='Overall test kits per capita',cex.lab=1.2,xlim=c(0,1.1*max(all_data_by_state2$testkits_per_capita_recent)))
text(all_data_by_state2$testkits_per_capita_recent,all_data_by_state2$doubling_time_first3weeks,labels = all_data_by_state2$abbr,cex=0.7,pos=4)
mtext(text = '(b)',side = 3,line = -1.5,adj = 0.95)

```



